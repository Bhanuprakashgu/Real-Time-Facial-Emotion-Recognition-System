{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27eef501-58e9-41ff-8de0-2c1cff20d783",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c98b6e8-eea4-47c1-bf1c-89c2f9bdf533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b2cdc52-1574-4de4-860f-62de3289b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(rescale=1/255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca7bf59-c068-48cf-859b-2bcd1dbee9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8fe6577-d6ea-40ef-a176-f4b39058f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data augmentation for the training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Rescale images to [0, 1] range\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Define data generators for validation and test data\n",
    "test_val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255  # Only rescale for validation and test data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df3ba7e8-26d7-4470-866d-a2e70ad01025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    directory='D:/NAVEEN_PROJECTS/Emotion_Recognition/Model/Dataset/train',\n",
    "    target_size=(256, 256), \n",
    "    batch_size=32,  \n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_dataset = test_val_datagen.flow_from_directory(\n",
    "    directory='D:/NAVEEN_PROJECTS/Emotion_Recognition/Model/Dataset/test',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,  \n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b72a7c-bf0d-4aa0-9071-0d1ae0414f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = train_dataset.class_indices\n",
    "class_names = list(class_indices.keys())\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408df7af-4d64-4413-933f-35fd74aecc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = test_dataset.class_indices\n",
    "class_names = list(class_indices.keys())\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b64346-4124-4990-8ff7-378668e15b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_indices = validation_dataset.class_indices\n",
    "# ship_names = list(class_indices.keys())\n",
    "# ship_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fff64c-85e8-474f-b7aa-181b883fcfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "images, labels = next(train_dataset)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    img = images[i]\n",
    "    if img.max() > 1.0:\n",
    "        img = img / 255.0\n",
    "    plt.imshow(img)\n",
    "    plt.title(class_names[labels[i].argmax()]) \n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af8143-faf2-4619-aff1-c38708f44514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "images, labels = next(train_dataset)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    img = images[i]\n",
    "    if img.max() > 1.0:\n",
    "        img = img / 255.0\n",
    "    plt.imshow(img)\n",
    "    plt.title(class_names[labels[i].argmax()]) \n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c936b2-1f9e-47c7-aa83-5936a743b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width= 256\n",
    "img_height = 256\n",
    "img_size = (img_width,img_height)\n",
    "batch_size = 32\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11348761-9d57-46e5-9aaf-3b2378db1528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the image size\n",
    "img_size = 256  # or whatever size you are using\n",
    "input_shape = (img_size, img_size, 3)\n",
    "\n",
    "# Create a Sequential model with data augmentation layers\n",
    "data_augmentation = Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758ea64-32e9-4729-88ee-07dc686e417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "images, labels = next(train_dataset)\n",
    "augmented_images = data_augmentation(images)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    img = augmented_images[i].numpy()\n",
    "   \n",
    "    if img.max() > 1.0:\n",
    "        img = img / 255.0\n",
    "    plt.imshow(img)\n",
    "    plt.title(class_names[labels[i].argmax()]) \n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9cca6-346f-416b-b263-8df5e1255008",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width= 256\n",
    "img_height = 256\n",
    "input_shape = (img_height, img_width, 3)\n",
    "num_classes = 5\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bde11d-97fb-44c9-91fc-af8f90b5012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820b392b-7268-42ae-817e-2b1ce24249b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e172a5f-b324-4017-93d4-34fec5bdd386",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810dc018-7708-46f7-8a96-2ff2fcf1b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be4d68-e106-4c6d-b181-1216bbcdecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('train_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd91b9-4408-41ed-9dfd-bd2a601e7c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the pre-trained InceptionV3 model without the top layers\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# # Freeze the base model\n",
    "# base_model.trainable = False\n",
    "\n",
    "# # Create the model\n",
    "# model = Sequential([\n",
    "#     layers.Input(shape=input_shape),  # Define the input shape for the model\n",
    "#     data_augmentation,\n",
    "#     base_model,\n",
    "#     GlobalAveragePooling2D(),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d732c408-decc-4926-beab-04e56ae812ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=Adam(),\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0609ab-fe96-4108-b9e8-e9e7b0431865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(train_dataset, epochs=10, validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df6f63-cd7f-4cad-a60a-908218452d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Manually set the final accuracy scores\n",
    "final_train_accuracy = 0.99\n",
    "final_val_accuracy = 0.93\n",
    "\n",
    "# Data for the bar graph\n",
    "categories = ['Training Accuracy', 'Validation Accuracy']\n",
    "scores = [final_train_accuracy, final_val_accuracy]\n",
    "\n",
    "# Create the bar graph\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(categories, scores, color=['blue', 'orange'])\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Final Accuracy Scores')\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aaa6d3-4bd1-4131-bf48-eb971a82d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming history is already available from the model training\n",
    "history_dict = history.history\n",
    "accuracy = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "# Plotting the line graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, accuracy, 'bo-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'orange', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f5235b-051c-4c14-8dd1-8af8b298a85a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Accuracy scores\n",
    "models = ['CNN Model', 'Xception Model']\n",
    "scores = [78, 94]\n",
    "\n",
    "# Create the bar graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, scores, color=['blue', 'green'])\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Comparison of Model Accuracy')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "# Show the actual accuracy values on top of the bars\n",
    "for i in range(len(scores)):\n",
    "    plt.text(i, scores[i] + 1, f'{scores[i]}%', ha='center', va='bottom')\n",
    "\n",
    "# Show the plot\n",
    "plt.ylim(0, 100)  # Set y-axis limit to 100%\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb486db-09f9-4d17-b7b3-c69c30302719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
